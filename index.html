<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Your Name</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Charter', 'Georgia', 'Times New Roman', serif;
            line-height: 1.65;
            color: #2c2c2c;
            background: #fdfdfd;
            font-size: 16px;
        }

        /* Typography */
        h1, h2, h3 {
            font-family: 'Charter', 'Georgia', serif;
            font-weight: normal;
            color: #1a1a1a;
            margin-bottom: 0.5em;
        }

        h1 { font-size: 2.2em; }
        h2 { font-size: 1.5em; margin-top: 2.5em; }
        h3 { font-size: 1.2em; margin-top: 1.5em; }

        p { margin-bottom: 1.2em; }
        a { color: #2563eb; text-decoration: none; }
        a:hover { text-decoration: underline; }

        /* Layout */
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 3em 2em;
            padding-top: 6.5em; /* Add space for fixed navbar */
        }

        /* Header */
        .header {
            padding-bottom: 2em;
            margin-bottom: 3em;
        }

        .name {
            font-size: 2.2em;
            font-weight: normal;
            margin-bottom: 0.2em;
        }

        .title-line {
            font-size: 1.1em;
            color: #666;
            margin-bottom: 1em;
        }

        .contact-line {
            font-size: 0.95em;
            color: #666;
        }

        .contact-line a {
            color: #666;
            margin-right: 1.5em;
        }

        .contact-line a:hover {
            color: #2563eb;
        }

        /* Navigation */
        .nav {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            background: rgba(253, 253, 253, 0.92);
            backdrop-filter: blur(8px);
            -webkit-backdrop-filter: blur(8px);
        }

        .nav-container {
            max-width: 800px;
            margin: 0 auto;
            padding: 0 2em;
            display: flex;
            align-items: center;
            justify-content: space-between;
            height: 52px;
        }

        .nav-name {
            font-size: 0.95em;
            color: #2c2c2c;
            font-weight: normal;
            letter-spacing: 0.01em;
        }

        .nav-tabs {
            display: flex;
            gap: 2.5em;
            margin: 0;
        }

        .nav a.nav-link {
            position: relative;
            color: #888;
            font-size: 0.9em;
            padding: 0;
            transition: color 0.3s ease;
            font-weight: normal;
        }

        .nav a.nav-link:hover {
            color: #2c2c2c;
            text-decoration: none;
        }

        .nav a.nav-link.active {
            color: #2c2c2c;
        }

        /* Subtle underline animation */
        .nav a.nav-link::after {
            content: '';
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 0;
            height: 1px;
            background: #2c2c2c;
            transition: width 0.3s ease;
        }

        .nav a.nav-link:hover::after,
        .nav a.nav-link.active::after {
            width: 100%;
        }

        /* Sections */
        .section {
            margin-bottom: 3em;
        }

        .section-title {
            font-size: 1.5em;
            margin-bottom: 1.5em;
            border-bottom: 1px solid #e5e5e5;
            padding-bottom: 0.5em;
        }

        /* Research interests */
        .interests {
            margin: 1.5em 0;
            font-style: italic;
            color: #555;
        }

        /* Projects */
        .project {
            margin-bottom: 2.5em;
            padding-bottom: 2em;
            border-bottom: 1px solid #f0f0f0;
        }

        .project:last-child {
            border-bottom: none;
        }

        .project-title {
            font-size: 1.15em;
            font-weight: normal;
            margin-bottom: 0.3em;
        }

        .project-meta {
            font-size: 0.9em;
            color: #666;
            margin-bottom: 0.8em;
        }

        .project-description {
            margin-bottom: 0.8em;
        }

        .project-links {
            font-size: 0.9em;
        }

        .project-links a {
            margin-right: 1em;
        }

        /* News */
        .news-item {
            margin-bottom: 1.5em;
            display: flex;
            gap: 1.5em;
        }

        .news-date {
            flex-shrink: 0;
            width: 80px;
            font-size: 0.9em;
            color: #666;
            font-variant-numeric: tabular-nums;
        }

        .news-content {
            flex: 1;
        }

        .news-title {
            font-weight: normal;
            margin-bottom: 0.3em;
        }

        .news-description {
            font-size: 0.95em;
            color: #555;
        }

        /* Publications list */
        .publication {
            margin-bottom: 2em;
            padding-left: 1.5em;
            text-indent: -1.5em;
        }

        .publication-title {
            font-weight: normal;
        }

        .publication-authors {
            color: #555;
        }

        .publication-venue {
            font-style: italic;
            color: #666;
        }

        /* Simple responsive */
        @media (max-width: 768px) {
            .container {
                padding: 2em 1.5em;
                padding-top: 5.5em; /* Adjust for smaller navbar on mobile */
            }

            .name {
                font-size: 1.8em;
            }

            .contact-line a {
                display: block;
                margin-bottom: 0.3em;
                margin-right: 0;
            }

            .nav-container {
                padding: 0 1.5em;
                height: 48px;
            }

            .nav-name {
                font-size: 0.9em;
            }

            .nav-tabs {
                gap: 1.5em;
            }

            .nav a.nav-link {
                font-size: 0.85em;
            }

            .news-item {
                flex-direction: column;
                gap: 0.3em;
            }

            .news-date {
                width: auto;
            }
        }

        /* Minimal hover effects */
        .project:hover {
            background: #fafafa;
            margin-left: -1em;
            margin-right: -1em;
            padding-left: 1em;
            padding-right: 1em;
            border-radius: 2px;
        }

        /* Typography refinements */
        .intro-text {
            font-size: 1.05em;
            line-height: 1.7;
        }

        /* Status indicators */
        .status {
            font-size: 0.85em;
            color: #666;
            font-variant: small-caps;
        }

        .status.published { color: #0f5132; }
        .status.ongoing { color: #b45309; }
        .status.submitted { color: #1e40af; }

        /* Clean focus states */
        a:focus {
            outline: 2px solid #2563eb;
            outline-offset: 2px;
        }

        /* Scroll animations */
        .section {
            opacity: 0;
            transform: translateY(30px);
            transition: opacity 0.6s ease, transform 0.6s ease;
        }

        .section.visible {
            opacity: 1;
            transform: translateY(0);
        }

        /* Stagger animation for child elements */
        .section.visible .project,
        .section.visible .news-item,
        .section.visible p {
            animation: fadeInUp 0.5s ease forwards;
        }

        .section.visible .project:nth-child(1) { animation-delay: 0.1s; }
        .section.visible .project:nth-child(2) { animation-delay: 0.2s; }
        .section.visible .project:nth-child(3) { animation-delay: 0.3s; }
        .section.visible .project:nth-child(4) { animation-delay: 0.4s; }

        .section.visible .news-item:nth-child(1) { animation-delay: 0.1s; }
        .section.visible .news-item:nth-child(2) { animation-delay: 0.15s; }
        .section.visible .news-item:nth-child(3) { animation-delay: 0.2s; }
        .section.visible .news-item:nth-child(4) { animation-delay: 0.25s; }
        .section.visible .news-item:nth-child(5) { animation-delay: 0.3s; }
        .section.visible .news-item:nth-child(6) { animation-delay: 0.35s; }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Initial state for animated elements */
        .project,
        .news-item,
        #misc p {
            opacity: 0;
        }

        /* Print styles */
        @media print {
            body { font-size: 12pt; }
            .nav { display: none; }
            a { color: #000; }
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav class="nav">
        <div class="nav-container">
            <div class="nav-name">Eyon Jang</div>
            <div class="nav-tabs">
                <a href="#intro" class="nav-link active">About</a>
                <a href="#research" class="nav-link">Research</a>
                <a href="#news" class="nav-link">News</a>
                <a href="#misc" class="nav-link">Misc</a>
                <a href="#contact" class="nav-link">Contact</a>
            </div>
        </div>
    </nav>

    <div class="container">
        <!-- Header -->
        <header class="header">
            <h1 class="name">Eyon Jang</h1>
            <div class="title-line">AI Safety Researcher, [Your Institution]</div>
            <div class="contact-line">
                <a href="mailto:yjang385@gmail.com">Email</a>
                <a href="https://linkedin.com/in/yeonwoojang">LinkedIn</a>
                <a href="https://scholar.google.com/citations?user=jXfklAEAAAAJ&sortby=pubdate">Scholar</a>
                <a href="https://x.com/yoenoo_">X</a>
                <a href="/cv.pdf">CV</a>
            </div>
        </header>

        <!-- Introduction -->
        <section id="intro" class="section visible">
            <h2 class="section-title">Introduction</h2>
            <div class="intro-text">
                <p>
                    I work on ensuring that artificial intelligence systems remain beneficial and aligned 
                    with human values as they become more capable. My research focuses on developing 
                    methods for understanding, evaluating, and controlling advanced AI systems.
                </p>
                <p>
                    Currently, I am investigating techniques for mechanistic interpretability of large 
                    language models, robust evaluation methods for AI safety, and scalable approaches 
                    to AI alignment. I am particularly interested in the challenge of maintaining 
                    alignment as AI systems become more capable than their human overseers.
                </p>
            </div>
            <div class="interests">
                Research interests: AI alignment, mechanistic interpretability, robustness evaluation, 
                mesa-optimization, value learning, AI governance
            </div>
        </section>

        <!-- Research -->
        <section id="research" class="section">
            <h2 class="section-title">Research</h2>
            
            <div class="project">
                <h3 class="project-title">Constitutional AI: Harmlessness from AI Feedback</h3>
                <div class="project-meta">
                    <span class="status published">published</span> · 
                    NeurIPS 2024 · 
                    with Research Partner, Senior Collaborator
                </div>
                <div class="project-description">
                    We present a method for training AI systems to be harmless through constitutional learning, 
                    where models learn to critique and revise their outputs according to a set of principles. 
                    Our approach shows significant reductions in harmful outputs while maintaining helpfulness.
                </div>
                <div class="project-links">
                    <a href="#">paper</a>
                    <a href="#">code</a>
                    <a href="#">blog</a>
                </div>
            </div>

            <div class="project">
                <h3 class="project-title">Mechanistic Analysis of Mesa-Optimization in Language Models</h3>
                <div class="project-meta">
                    <span class="status ongoing">ongoing</span> · 
                    2024–2025 · 
                    with Interpretability Team
                </div>
                <div class="project-description">
                    Investigation of whether large language models develop internal optimization processes 
                    that could pursue goals different from the training objective. We use interpretability 
                    techniques to identify and analyze optimization-like structures in trained models.
                </div>
                <div class="project-links">
                    <a href="#">draft</a>
                    <a href="#">demo</a>
                </div>
            </div>

            <div class="project">
                <h3 class="project-title">Adversarial Robustness of AI Safety Evaluations</h3>
                <div class="project-meta">
                    <span class="status published">published</span> · 
                    AAAI 2024 · 
                    with Safety Evaluation Team
                </div>
                <div class="project-description">
                    Systematic testing of AI safety evaluation methods against optimization pressure and 
                    deception. We identify critical vulnerabilities in current approaches that could lead 
                    to dangerous overconfidence in system safety assessments.
                </div>
                <div class="project-links">
                    <a href="#">paper</a>
                    <a href="#">evaluation suite</a>
                    <a href="#">policy brief</a>
                </div>
            </div>

            <div class="project">
                <h3 class="project-title">Scalable Oversight for Superhuman AI Systems</h3>
                <div class="project-meta">
                    <span class="status submitted">under review</span> · 
                    submitted to ICML 2025 · 
                    with Alignment Research Group
                </div>
                <div class="project-description">
                    Exploring methods for aligning AI systems that exceed human capabilities in specific domains. 
                    We investigate whether weak human supervision can generalize to strong AI capabilities 
                    and develop techniques for scalable oversight mechanisms.
                </div>
                <div class="project-links">
                    <a href="#">preprint</a>
                    <a href="#">appendix</a>
                </div>
            </div>
        </section>

        <!-- News -->
        <section id="news" class="section">
            <h2 class="section-title">News</h2>
            
            <div class="news-item">
                <div class="news-date">Aug 2025</div>
                <div class="news-content">
                    <div class="news-title">Keynote at AI Safety Summit</div>
                    <div class="news-description">
                        Presenting our robustness evaluation work at the International AI Safety Summit in London.
                    </div>
                </div>
            </div>

            <div class="news-item">
                <div class="news-date">Jul 2025</div>
                <div class="news-content">
                    <div class="news-title">Grant from Future of Humanity Institute</div>
                    <div class="news-description">
                        Received £500K grant to study mesa-optimization in large language models over three years.
                    </div>
                </div>
            </div>

            <div class="news-item">
                <div class="news-date">Jun 2025</div>
                <div class="news-content">
                    <div class="news-title">Paper accepted to NeurIPS 2025</div>
                    <div class="news-description">
                        "Scalable Oversight for Superhuman AI Systems" accepted to NeurIPS 2025.
                    </div>
                </div>
            </div>

            <div class="news-item">
                <div class="news-date">May 2025</div>
                <div class="news-content">
                    <div class="news-title">Editorial board appointment</div>
                    <div class="news-description">
                        Joined the editorial board of the <em>Journal of AI Safety Research</em> as Associate Editor.
                    </div>
                </div>
            </div>

            <div class="news-item">
                <div class="news-date">Apr 2025</div>
                <div class="news-content">
                    <div class="news-title">Guest lecture at Stanford</div>
                    <div class="news-description">
                        Gave lecture on "Constitutional AI and Value Alignment" for CS229. 
                        <a href="#">Slides available here</a>.
                    </div>
                </div>
            </div>

            <div class="news-item">
                <div class="news-date">Mar 2025</div>
                <div class="news-content">
                    <div class="news-title">Commentary in <em>Nature AI</em></div>
                    <div class="news-description">
                        Co-authored commentary on robust evaluation methods for AI safety. 
                        <a href="#">Read here</a>.
                    </div>
                </div>
            </div>
        </section>

        <!-- Misc -->
        <section id="misc" class="section">
            <h2 class="section-title">Miscellaneous</h2>
            
            <h3 style="font-size: 1.1em; margin-bottom: 1em; color: #2c2c2c;">Mentoring</h3>
            <p style="margin-bottom: 1.5em;">
                I enjoy mentoring students interested in AI safety research. I currently supervise 3 PhD students 
                and regularly mentor undergraduate researchers through the AI Safety Scholars program. 
                If you're interested in working together, please reach out with your background and research interests.
            </p>
            
            <h3 style="font-size: 1.1em; margin-bottom: 1em; color: #2c2c2c;">Teaching</h3>
            <p style="margin-bottom: 1.5em;">
                <strong>CS 401: Advanced Topics in AI Safety</strong> (Spring 2025)<br>
                <span style="color: #666; font-size: 0.95em;">Graduate seminar covering alignment, interpretability, and robustness</span><br><br>
                
                <strong>CS 201: Introduction to Machine Learning</strong> (Fall 2024)<br>
                <span style="color: #666; font-size: 0.95em;">Undergraduate course with special emphasis on responsible AI development</span>
            </p>
            
            <h3 style="font-size: 1.1em; margin-bottom: 1em; color: #2c2c2c;">Service</h3>
            <p style="margin-bottom: 1.5em;">
                <strong>Program Committee:</strong> NeurIPS 2025, ICML 2025, AAAI 2025, AI Safety Workshop 2024<br>
                <strong>Reviewer:</strong> Nature Machine Intelligence, Journal of AI Research<br>
                <strong>Organizer:</strong> Monthly AI Safety Reading Group, Annual Safety Research Symposium
            </p>
            
            <h3 style="font-size: 1.1em; margin-bottom: 1em; color: #2c2c2c;">Selected Talks</h3>
            <p style="margin-bottom: 1.5em;">
                "The Alignment Problem: Technical Challenges and Solutions" — <em>MIT AI Colloquium, Oct 2024</em><br>
                "Mechanistic Interpretability at Scale" — <em>DeepMind Research Seminar, Sep 2024</em><br>
                "Building Robust AI Evaluations" — <em>Stanford EA Conference, May 2024</em>
            </p>
            
            <h3 style="font-size: 1.1em; margin-bottom: 1em; color: #2c2c2c;">Other Interests</h3>
            <p>
                Outside of research, I enjoy hiking, playing chess (1800 ELO on chess.com), 
                and contributing to open-source AI safety tools. I'm also involved in effective altruism 
                and regularly participate in AI governance discussions.
            </p>
        </section>

        <!-- Contact -->
        <section id="contact" class="section">
            <h2 class="section-title">Contact</h2>
            <p>
                I welcome discussions about research collaborations, particularly on AI alignment, 
                interpretability, and safety evaluation. I'm happy to talk with researchers at all 
                career stages.
            </p>
            <p>
                <strong>Email:</strong> <a href="mailto:your.email@domain.com">your.email@domain.com</a><br>
                <strong>Office:</strong> Building Name, Room 456<br>
                <strong>Office hours:</strong> Tuesdays 2–4 PM (by appointment)
            </p>
        </section>
    </div>

    <script>
        // Simple smooth scrolling and active tab management
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                    
                    // Update active tab
                    if (this.classList.contains('nav-link')) {
                        document.querySelectorAll('.nav-link').forEach(link => {
                            link.classList.remove('active');
                        });
                        this.classList.add('active');
                    }
                }
            });
        });

        // Intersection Observer for scroll animations
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const sectionObserver = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, observerOptions);

        // Observe all sections
        document.querySelectorAll('.section').forEach(section => {
            sectionObserver.observe(section);
        });

        // Update active tab on scroll
        window.addEventListener('scroll', () => {
            const sections = document.querySelectorAll('.section');
            const navLinks = document.querySelectorAll('.nav-link');
            
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop - 100;
                if (window.pageYOffset >= sectionTop) {
                    current = section.getAttribute('id');
                }
            });

            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === `#${current}`) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>
